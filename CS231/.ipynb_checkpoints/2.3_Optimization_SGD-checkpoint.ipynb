{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Introductions\" data-toc-modified-id=\"Introductions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introductions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Classifier-three-components:\" data-toc-modified-id=\"Classifier-three-components:-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Classifier three components:</a></span></li><li><span><a href=\"#Extension-of-the-3-components-when-applying-DNN-or-CNN:\" data-toc-modified-id=\"Extension-of-the-3-components-when-applying-DNN-or-CNN:-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Extension of the 3 components when applying DNN or CNN:</a></span></li></ul></li><li><span><a href=\"#Visualizing-the-loss-function\" data-toc-modified-id=\"Visualizing-the-loss-function-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Visualizing the loss function</a></span></li><li><span><a href=\"#Optimization\" data-toc-modified-id=\"Optimization-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Optimization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Strategy-#1:-A-first-very-bad-idea-solution:-Random-search-(15.5%,-kiding??)\" data-toc-modified-id=\"Strategy-#1:-A-first-very-bad-idea-solution:-Random-search-(15.5%,-kiding??)-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Strategy #1: A first very bad idea solution: Random search (15.5%, kiding??)</a></span></li><li><span><a href=\"#Strategy-#2:-Random-Local-Search-(21.4%)\" data-toc-modified-id=\"Strategy-#2:-Random-Local-Search-(21.4%)-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Strategy #2: Random Local Search (21.4%)</a></span></li><li><span><a href=\"#Strategy-#3:-Following-the-Gradient\" data-toc-modified-id=\"Strategy-#3:-Following-the-Gradient-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Strategy #3: Following the Gradient</a></span></li></ul></li><li><span><a href=\"#Computing-the-gradient\" data-toc-modified-id=\"Computing-the-gradient-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Computing the gradient</a></span><ul class=\"toc-item\"><li><span><a href=\"#Computing-the-gradient-numerically-with-finite-differences\" data-toc-modified-id=\"Computing-the-gradient-numerically-with-finite-differences-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Computing the gradient numerically with finite differences</a></span></li><li><span><a href=\"#Computing-the-gradient-analytically-with-Calculus\" data-toc-modified-id=\"Computing-the-gradient-analytically-with-Calculus-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Computing the gradient analytically with Calculus</a></span></li></ul></li><li><span><a href=\"#Gradient-Descent\" data-toc-modified-id=\"Gradient-Descent-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Gradient Descent</a></span><ul class=\"toc-item\"><li><span><a href=\"#Mini-batch-gradient-descent.\" data-toc-modified-id=\"Mini-batch-gradient-descent.-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Mini-batch gradient descent.</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Optimization: Stochastic Gradient Descent](http://cs231n.github.io/optimization-1/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introductions\n",
    "\n",
    "### Classifier three components:\n",
    "* [<span class=\"burk\">forward pass</span>] A (parameterized) **<span class=\"girk\">score function</span>** mapping the raw image pixels to class scores (e.g. a linear function)\n",
    "* <span class=\"burk\">[backward pass</span>] A **<span class=\"girk\">loss function</span>** that measured the quality of a particular set of parameters based on how well the induced scores agreed with the ground truth labels in the training data. We saw that there are many ways and versions of this (e.g. Softmax/SVM).\n",
    "* **<span class=\"girk\">Optimization</span>** is the process of finding the set of parameters $W$ that minimize the loss function.\n",
    "\n",
    "### Extension of the 3 components when applying DNN or CNN:\n",
    "* we will <span class=\"girk\">revisit the first component (the parameterized function mapping)</span> and extend it to functions much more complicated than a linear mapping: First entire Neural Networks, and then Convolutional Neural Networks\n",
    "* The loss functions and the optimization process will remain relatively unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the loss function\n",
    "* 该节介绍的 对 loss function visualizing 的方法比较有趣, 以后可以借鉴.\n",
    "* 通过设置 random parameters (weights), 然后再 random 方向上改变 parameter 可以改变 weights, 画出 loss function energy, 对样本平均之后可以看出 loss function 的形状.\n",
    "* 具体内容看网页内容."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "* The optimization tools used in this section is only suitable for SVM (and other convex loss function), not suitable for NN. \n",
    "\n",
    "\n",
    "### Strategy #1: A first very bad idea solution: Random search (15.5%, kiding??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assume X_train is the data where each column is an example (e.g. 3073 x 50,000)\n",
    "# assume Y_train are the labels (e.g. 1D array of 50,000)\n",
    "# assume the function L evaluates the loss function\n",
    "\n",
    "bestloss = float(\"inf\") # Python assigns the highest possible float value\n",
    "for num in xrange(1000):\n",
    "  W = np.random.randn(10, 3073) * 0.0001 # generate random parameters\n",
    "  loss = L(X_train, Y_train, W) # get the loss over the entire training set\n",
    "  if loss < bestloss: # keep track of the best solution\n",
    "    bestloss = loss\n",
    "    bestW = W\n",
    "  print 'in attempt %d the loss was %f, best %f' % (num, loss, bestloss)\n",
    "\n",
    "# prints:\n",
    "# in attempt 0 the loss was 9.401632, best 9.401632\n",
    "# in attempt 1 the loss was 8.959668, best 8.959668\n",
    "# in attempt 2 the loss was 9.044034, best 8.959668\n",
    "# in attempt 3 the loss was 9.278948, best 8.959668\n",
    "# in attempt 4 the loss was 8.857370, best 8.857370\n",
    "# in attempt 5 the loss was 8.943151, best 8.857370\n",
    "# in attempt 6 the loss was 8.605604, best 8.605604\n",
    "# ... (trunctated: continues for 1000 lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy #2: Random Local Search (21.4%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = np.random.randn(10, 3073) * 0.001 # generate random starting W\n",
    "bestloss = float(\"inf\")\n",
    "for i in xrange(1000):\n",
    "  step_size = 0.0001\n",
    "  Wtry = W + np.random.randn(10, 3073) * step_size\n",
    "  loss = L(Xtr_cols, Ytr, Wtry)\n",
    "  if loss < bestloss:\n",
    "    W = Wtry\n",
    "    bestloss = loss\n",
    "  print 'iter %d loss is %f' % (i, bestloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy #3: Following the Gradient\n",
    "\n",
    "## Computing the gradient\n",
    "* A <span class=\"girk\">slow, approximate</span> but <span class=\"girk\">easy</span> way (numerical gradient)\n",
    "* a <span class=\"girk\">fast</span>, exact but <span class=\"girk\">more error-prone way</span> that <span class=\"girk\">requires calculus</span> (analytic gradient)\n",
    "\n",
    "### Computing the gradient numerically with finite differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_numerical_gradient(f, x):\n",
    "  \"\"\" \n",
    "  a naive implementation of numerical gradient of f at x \n",
    "  - f should be a function that takes a single argument\n",
    "  - x is the point (numpy array) to evaluate the gradient at\n",
    "  \"\"\" \n",
    "\n",
    "  fx = f(x) # evaluate function value at original point\n",
    "  grad = np.zeros(x.shape)\n",
    "  h = 0.00001\n",
    "\n",
    "  # iterate over all indexes in x\n",
    "  it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "  while not it.finished:\n",
    "\n",
    "    # evaluate function at x+h\n",
    "    ix = it.multi_index\n",
    "    old_value = x[ix]\n",
    "    x[ix] = old_value + h # increment by h\n",
    "    fxh = f(x) # evalute f(x + h)\n",
    "    x[ix] = old_value # restore to previous value (very important!)\n",
    "\n",
    "    # compute the partial derivative\n",
    "    grad[ix] = (fxh - fx) / h # the slope\n",
    "    it.iternext() # step to next dimension\n",
    "\n",
    "  return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Practical considerations. \n",
    "Additionally, in practice it often works better to compute the numeric gradient using the **centered difference formula**: $[f(x+h) - f(x-h)] / 2 h$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to use the generic code above we want a function that takes a single argument\n",
    "# (the weights in our case) so we close over X_train and Y_train\n",
    "def CIFAR10_loss_fun(W):\n",
    "  return L(X_train, Y_train, W)\n",
    "\n",
    "W = np.random.rand(10, 3073) * 0.001 # random weight vector\n",
    "df = eval_numerical_gradient(CIFAR10_loss_fun, W) # get the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient tells us the slope of the loss function along every dimension, which we can use to make an update:\n",
    "\n",
    "这里 上下 cell 之间存在调用关系\n",
    "\n",
    "##### Update in negative gradient direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_original = CIFAR10_loss_fun(W) # the original loss\n",
    "print 'original loss: %f' % (loss_original, )\n",
    "\n",
    "# lets see the effect of multiple step sizes\n",
    "for step_size_log in [-10, -9, -8, -7, -6, -5,-4,-3,-2,-1]:\n",
    "  step_size = 10 ** step_size_log\n",
    "  W_new = W - step_size * df # new position in the weight space\n",
    "  loss_new = CIFAR10_loss_fun(W_new)\n",
    "  print 'for step size %f new loss: %f' % (step_size, loss_new)\n",
    "\n",
    "# prints:\n",
    "# original loss: 2.200718\n",
    "# for step size 1.000000e-10 new loss: 2.200652\n",
    "# for step size 1.000000e-09 new loss: 2.200057\n",
    "# for step size 1.000000e-08 new loss: 2.194116\n",
    "# for step size 1.000000e-07 new loss: 2.135493\n",
    "# for step size 1.000000e-06 new loss: 1.647802\n",
    "# for step size 1.000000e-05 new loss: 2.844355\n",
    "# for step size 1.000000e-04 new loss: 25.558142\n",
    "# for step size 1.000000e-03 new loss: 254.086573\n",
    "# for step size 1.000000e-02 new loss: 2539.370888\n",
    "# for step size 1.000000e-01 new loss: 25392.214036"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Effect of step size.\n",
    "从上面 code 运行结果可以看出, steps size 很重要, 不要太大也不要太小.\n",
    "* choosing the step size (also called the learning rate) will become one of the most important (and most headache-inducing) hyperparameter settings in training a neural network.\n",
    "* If we shuffle our feet carefully we can expect to make consistent but very small progress (this corresponds to having a small step size). 对于非凸问题, 走不出local-minum.\n",
    "* Conversely, we can choose to make a large, confident step in an attempt to descend faster, but this may not pay off. As you can see in the code example above, at some point taking a bigger step gives a higher loss as we “overstep”.\n",
    "\n",
    "##### A problem of efficiency.\n",
    "* we had 30730 parameters in total and therefore had to perform 30,731 evaluations of the loss function to evaluate the gradient and to perform only a single parameter update. \n",
    "* This problem only gets worse, since modern Neural Networks can easily have tens of millions of parameters. Clearly, this strategy is not scalable and we need something better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the gradient analytically with Calculus\n",
    "* The numerical gradient is very simple to compute using the finite difference approximation, \n",
    "    * but **<span class=\"burk\">the downside</span>** is that it is approximate (since we have to pick a small value of $h$, \n",
    "    * while the true gradient is defined as the limit as $h$ goes to zero), and that it is very computationally expensive to compute.\n",
    "    \n",
    "    \n",
    "    \n",
    "* The 2nd way to compute the gradient is <span class=\"girk\">analytically using Calculus</span>, which allows us to derive a direct formula for the gradient (no approximations) that is also very fast to compute. \n",
    "    * unlike the numerical gradient it can be <span class=\"girk\">more error prone to implement</span>, which is why in practice it is very common to <span class=\"girk\">compute the analytic gradient</span> and <span class=\"girk\">compare it to the numerical gradient</span> to check the correctness of your implementation\n",
    "    * This is called a <span class=\"girk\">gradient check</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vanilla Gradient Descent\n",
    "while True:\n",
    "  weights_grad = evaluate_gradient(loss_fun, data, weights)\n",
    "  weights += - step_size * weights_grad # perform parameter update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This simple loop is at the core of all Neural Network libraries.\n",
    "* There are other ways of performing the optimization (e.g. LBFGS), but Gradient Descent is currently by far the most common and established way of optimizing Neural Network loss functions.\n",
    "\n",
    "\n",
    "### Mini-batch gradient descent.\n",
    "* In large-scale applications (such as the ILSVRC challenge), the training data can have <span class=\"girk\">on order of millions of examples</span>. Hence, it seems <span class=\"girk\">wasteful to compute</span> the full loss function over the <span class=\"girk\">entire training se</span>t in order to <span class=\"girk\">perform only a single parameter update</span>\n",
    "\n",
    "\n",
    "* A very common approach to addressing this challenge is to compute the gradient over <span class=\"girk\">batches</span> of the training data.\n",
    "    * For example, in current state of the art <span class=\"girk\">ConvNets</span>, a typical batch contains <span class=\"girk\">256 examples</span> from the entire training set of 1.2 million. \n",
    "    * This batch is then used to perform a parameter update:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vanilla Minibatch Gradient Descent\n",
    "\n",
    "while True:\n",
    "  data_batch = sample_training_data(data, 256) # sample 256 examples\n",
    "  weights_grad = evaluate_gradient(loss_fun, data_batch, weights)\n",
    "  weights += - step_size * weights_grad # perform parameter update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 物理上说明 batch 合理性: ILSVRC 1.2 million images, \n",
    "    * only 1000 unique images (one for each class, or in other words 1200 identical copies of each image).\n",
    "    * compute for all 1200 identical copies would all be the same, and when we average the data loss over all 1.2 million images we would get the exact same loss as if we only evaluated on a small subset of 1000.\n",
    "    \n",
    "\n",
    "* Extreme cases: mini-batch contains only a single example\n",
    "    * This process is called **Stochastic Gradient Descent (SGD) ** (or also sometimes **on-line gradient descent**). \n",
    "    * it is relatively <span class=\"girk\">less common</span> to see because in practice due to <span class=\"girk\">vectorized code optimizations</span> it can be computationally much more efficient to evaluate the <span class=\"girk\">gradient for 100 examples</span>, than <span class=\"girk\">the gradient for one example 100 times</span>.\n",
    "    \n",
    "* 关于称呼: Even though <span class=\"girk\">SGD</span> technically refers to <span class=\"girk\">using a single example at a time</span> to evaluate the gradient, you will hear people use the term SGD even when referring to <span class=\"girk\">mini-batch gradient descent</span> (i.e. mentions of <span class=\"girk\">MGD</span> for “<span class=\"girk\">Minibatch Gradient Descent</span>”, or <span class=\"girk\">BGD</span> for “<span class=\"girk\">Batch gradient descent</span>” are rare to see).\n",
    "\n",
    "* The size of the mini-batch is a <span class=\"girk\">hyperparameter</span> but it is <span class=\"girk\">not very common</span> to <span class=\"girk\">cross-validate</span> it.\n",
    "    * It is usually based on memory constraints (if any), or set to some value, e.g. <span class=\"girk\">32, 64 or 128</span>. \n",
    "    * We use <span class=\"girk\">powers of 2</span> in practice because many vectorized operation implementations <span class=\"girk\">work faster</span> when their inputs are sized in powers of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "![](http://cs231n.github.io/assets/dataflow.jpeg)\n",
    "Figure. Score function vs. Loss function in the pipelines.\n",
    "\n",
    "* step size (or the learning rate) that must be set just right\n",
    "* computing the numerical and analytic gradient. gradient check\n",
    "* Gradient Descent. Mini-batch gradient descent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
